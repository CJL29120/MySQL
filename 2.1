事务隔离：
  在MySQL中，事务支持是在引擎层实现的。
  MySQL原生的MyISAM引擎不支持事务。
  
  ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）;
  当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、
  幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。
  
  事务隔离得越严实，效率就会越低。因此很多时候，要在二者之间寻找一个平衡点。
  SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和
  串行化（serializable ）。
  解释：
  *读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
  *读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
  *可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。
    当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
  *串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，
    后访问的事务必须等前一个事务执行完成，才能继续执行。
    
   *读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。
   *读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。
   *可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。
   *串行：我的事务尚未提交，别人就别想改数据。
   这4种隔离级别，并行性能依次降低，安全性依次提高。
   
  在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。
    *在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
    *在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。
    *这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；
    *而“串行化”隔离级别下直接用加锁的方式来避免并行访问。
  
    不同隔离级别ReadView实现方式
    1. read-commited:
      即：在每次语句执行的过程中，都关闭read_view, 重新在row_search_for_mysql函数中创建当前的一份read_view。
      这样就会产生不可重复读现象发生。

    2. repeatable read：
      在repeatable read的隔离级别下，创建事务trx结构的时候，就生成了当前的global read view。
      使用trx_assign_read_view函数创建，一直维持到事务结束。在事务结束这段时间内 每一次查询都不会重新重建Read View ，
      从而实现了可重复读。

****************************************************************************************************
  Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，
  一定要记得将MySQL的隔离级别设置为“读提交”。
  
  什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。
    假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，
    也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，
    即使有用户发生了一笔新的交易，也不影响你的校对结果。
    这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。
    
  事务启动方式有以下几种：
    *显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。
    *set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，
      而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。
    
  为什么建议你尽量不要使用长事务。
    *长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，
      数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
    *除此之外，长事务还占用锁资源，可能会拖垮库。
  
  尝试回答这些问题检查自己的掌握程度:
    1.事务的概念是什么?
    2.mysql的事务隔离级别读未提交, 读已提交, 可重复读, 串行各是什么意思?
    3.读已提交, 可重复读是怎么通过视图构建实现的?
    4.可重复读的使用场景举例? 对账的时候应该很有用?
    5.事务隔离是怎么通过read-view(读视图)实现的?
    6.并发版本控制(MCVV)的概念是什么, 是怎么实现的?
    7.使用长事务的弊病? 为什么使用常事务可能拖垮整个库?
    8.事务的启动方式有哪几种? 
    9.commit work and chain的语法是做什么用的? 
    10.怎么查询各个表中的长事务?
    11.如何避免长事务的出现?
  
  索引上：
    索引的常见模型：介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。
      哈希表：
        哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。
          哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。
        
        不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。

        数组存放的索引对应的key值并不是递增的，这样做的好处是增加value数据时速度会很快，只需要往后追加。但缺点是，
          因为不是有序的，所以哈希索引做区间查询的速度是很慢的。
        
        所以，哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。

      有序数组:
        有序数组在等值查询和范围查询场景中的性能就都非常优秀。
        通过二分法就可以快速得到存在数组里的数据。
        
        如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，
          你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。
          
      搜索树：
            树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。
         二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，
         还要写到磁盘上。
            你可以想象一下一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，
         从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，
         单独访问一个行可能需要20个10 ms的时间，这个查询可真够慢的。
            为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，
         而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。
            以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，
         这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，
            查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。
            N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。
      
      你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，
        这样才能从理论上分析出这个数据库的适用场景。
      
    根据叶子节点的内容，索引类型分为主键索引和非主键索引。
      *主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。
      *非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。
    根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？
      如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
      如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。
        这个过程称为回表。
      ****也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。***
    *******************************************************************************************************
        数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。
    而锁就是用来实现这些访问规则的重要数据结构。
    
    全局锁：命令是 Flush tables with read lock (FTWRL)。
        全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。
    当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、
    数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。
    
        全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都select出来存成文本。
        注意，在备份过程中整个库完全处于只读状态。
           *如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
           *如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。
        一个操作涉及两个表更新，如果没有锁，在第一个表操作后，进行备份。那备份数据就是不完整的。
        
        业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，
    你要对里面任何一个表做加字段操作，都是会被锁住的。
        
    表级锁：
        MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
        *表锁的语法是 lock tables … read/write。
            *在某个线程A中执行lock tables t1 read, t2 write; 
            1.这个语句，则 其他线程 写t1、读写t2的语句都会被阻塞。
            2.同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。
        
        *另一类表级的锁是MDL（metadata lock)。
            MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，
          如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，
          那么查询线程拿到的结果跟表结构对不上，肯定是不行的。
            在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。
              1.MDL读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
              2.MDL读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，
                其中一个要等另一个执行完才能开始执行。
        给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，一定要特别小心。
        
        如何安全地给小表加字段？
          首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，
          你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。
        
  表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有lock tables这样的语句，你需要追查一下，
    比较可能的情况是：
    1.要么是你的系统现在还在用MyISAM这类不支持事务的引擎，那要安排升级换引擎；
    2.要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，
      最后业务开发就是把lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。
    
  MDL会直到事务提交才释放，在做表结构变更的时候，一定要小心，不要导致锁住线上查询和更新。
*************************************************************************************************************
    MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。
      不支持行锁意味着并发控制只能使用表锁。
    
    **在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
    **如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
    
    假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到以下操作：
      1.从顾客A账户余额中扣除电影票价；
      2.给影院B的账户余额增加这张电影票价；
      3.记录一条交易日志。
      也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。当然，为了保证交易的原子性，
    我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？
      试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为它们要更新同一个影院账户的余额，
    需要修改同一行数据。
      根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，
    如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，
    提升了并发度。
    
  死锁和死锁检测：
    当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
    
    事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。
    当出现死锁以后，有两种策略：
      *一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。
      *另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。
        将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。
      正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且innodb_deadlock_detect的默认值本身就是on。
        主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。
      
    怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的CPU资源。
      1.一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，
    因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。
    而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。
      2.另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，
    那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行
    ，因为客户端很多。我见过一个应用，有600个客户端，这样即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，
    峰值并发数也可能要达到3000。
      因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改MySQL源码的人，
    也可以做在MySQL里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。
      
      可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，
    影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。
    这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。（即将总金额分成十行，操作时选其中的一行）
    
  总结：
    建议：
      如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。
      但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。
        减少死锁的主要方向，就是控制访问相同资源的并发事务量。
    
